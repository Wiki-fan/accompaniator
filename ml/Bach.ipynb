{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import structures\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'structures.Song'>\n"
     ]
    }
   ],
   "source": [
    "Songs = pickle.load(open(\"bach.pickle\", \"rb\"))\n",
    "\n",
    "print(type(Songs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chords = []\n",
    "max_len = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for song in Songs:\n",
    "    for track in song.tracks:\n",
    "        for chord in track.chords: \n",
    "            new_chord = np.zeros(5-len(chord.notes))\n",
    "            new_chord = np.append(np.array([note.number for note in chord.notes]), new_chord)\n",
    "          #  print(new_chord)\n",
    "            all_chords.append(new_chord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5665\n"
     ]
    }
   ],
   "source": [
    "print(len(all_chords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "unique_chords = np.unique(all_chords, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22. 23. 25. 29.  0.]\n",
      " [22. 23. 25. 30.  0.]\n",
      " [22. 23. 26. 31.  0.]\n",
      " ...\n",
      " [29. 31. 33.  0.  0.]\n",
      " [29. 32.  0.  0.  0.]\n",
      " [29. 33.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(unique_chords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325\n"
     ]
    }
   ],
   "source": [
    "size = len(unique_chords)\n",
    "unique_chords = list(unique_chords)\n",
    "coded_chords = []\n",
    "\n",
    "\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chord in all_chords:\n",
    "    for i, unique_chord in enumerate(unique_chords):\n",
    "        if np.array_equal(chord, unique_chord):\n",
    "            coded_chords.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5665\n"
     ]
    }
   ],
   "source": [
    "print(len(coded_chords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "remove_indexes = []\n",
    "\n",
    "for i, frec in enumerate(Counter(coded_chords).values()):\n",
    "    if frec == 1:\n",
    "        remove_indexes.append(i)\n",
    "        \n",
    "print(len(remove_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22. 23. 27. 30.  0.]\n",
      " [22. 23. 27. 32.  0.]\n",
      " [22. 24. 25. 29.  0.]\n",
      " ...\n",
      " [29. 31.  0.  0.  0.]\n",
      " [29. 32.  0.  0.  0.]\n",
      " [29. 33.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "unique_chords = np.delete(unique_chords, remove_indexes, axis=0)\n",
    "#coded_chords = np.delete(coded_chords, remove_indexes)\n",
    "\n",
    "print(unique_chords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246\n"
     ]
    }
   ],
   "source": [
    "size = len(unique_chords)\n",
    "coded_chords = []\n",
    "\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chord in all_chords:\n",
    "    for i, unique_chord in enumerate(unique_chords):\n",
    "        if np.array_equal(chord, unique_chord):\n",
    "            coded_chords.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5586\n"
     ]
    }
   ],
   "source": [
    "print(len(coded_chords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_chords = all_chords\n",
    "all_chords = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chord in old_chords:\n",
    "    for unique_chord in unique_chords:\n",
    "        if np.array_equal(chord, unique_chord):\n",
    "            all_chords.append(chord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5586\n"
     ]
    }
   ],
   "source": [
    "print(len(all_chords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "798.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5586 / 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [coded_chords[i:i + 7] for i in range(0, len(coded_chords)-6, 1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5580, 7)\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "data = np.reshape(data, (-1, 7))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(558, 6)\n",
      "(5022, 6)\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "\n",
    "X = data[:,0:6]\n",
    "y = data[:,6]\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size=0.9, random_state=0)\n",
    "print(test_X.shape)\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 31s - loss: 4.7371 - acc: 0.0589 - val_loss: 4.5209 - val_acc: 0.0556\n",
      "1 1\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 31s - loss: 4.6475 - acc: 0.0573 - val_loss: 4.4851 - val_acc: 0.0556\n",
      "1 2\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 31s - loss: 4.6392 - acc: 0.0540 - val_loss: 4.4978 - val_acc: 0.0520\n",
      "1 3\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 31s - loss: 4.6230 - acc: 0.0597 - val_loss: 4.4842 - val_acc: 0.0412\n",
      "1 4\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 31s - loss: 4.6089 - acc: 0.0573 - val_loss: 4.4878 - val_acc: 0.0645\n",
      "1 5\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 33s - loss: 4.6166 - acc: 0.0558 - val_loss: 4.5001 - val_acc: 0.0556\n",
      "1 6\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 36s - loss: 4.6164 - acc: 0.0581 - val_loss: 4.5174 - val_acc: 0.0556\n",
      "1 7\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 39s - loss: 4.6177 - acc: 0.0577 - val_loss: 4.4897 - val_acc: 0.0556\n",
      "1 8\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 33s - loss: 4.6157 - acc: 0.0566 - val_loss: 4.4995 - val_acc: 0.0484\n",
      "1 9\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 33s - loss: 4.7277 - acc: 0.0564 - val_loss: 4.5018 - val_acc: 0.0556\n",
      "2 1\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 38s - loss: 4.6579 - acc: 0.0526 - val_loss: 4.4740 - val_acc: 0.0556\n",
      "2 2\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 33s - loss: 4.6234 - acc: 0.0516 - val_loss: 4.4971 - val_acc: 0.0556\n",
      "2 3\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 39s - loss: 4.6338 - acc: 0.0544 - val_loss: 4.4795 - val_acc: 0.0556\n",
      "2 4\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 37s - loss: 4.6220 - acc: 0.0579 - val_loss: 4.4948 - val_acc: 0.0556\n",
      "2 5\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 35s - loss: 4.6135 - acc: 0.0568 - val_loss: 4.4738 - val_acc: 0.0556\n",
      "2 6\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 34s - loss: 4.6166 - acc: 0.0558 - val_loss: 4.4907 - val_acc: 0.0591\n",
      "2 7\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 34s - loss: 4.6209 - acc: 0.0589 - val_loss: 4.4969 - val_acc: 0.0556\n",
      "2 8\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 34s - loss: 4.6151 - acc: 0.0540 - val_loss: 4.4845 - val_acc: 0.0556\n",
      "2 9\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 35s - loss: 4.7332 - acc: 0.0544 - val_loss: 4.5225 - val_acc: 0.0412\n",
      "3 1\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 35s - loss: 4.6737 - acc: 0.0550 - val_loss: 4.4778 - val_acc: 0.0556\n",
      "3 2\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 35s - loss: 4.6369 - acc: 0.0564 - val_loss: 4.5032 - val_acc: 0.0556\n",
      "3 3\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 36s - loss: 4.6326 - acc: 0.0587 - val_loss: 4.5035 - val_acc: 0.0412\n",
      "3 4\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 36s - loss: 4.6181 - acc: 0.0556 - val_loss: 4.5018 - val_acc: 0.0412\n",
      "3 5\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 37s - loss: 4.6098 - acc: 0.0564 - val_loss: 4.4872 - val_acc: 0.0556\n",
      "3 6\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 37s - loss: 4.6066 - acc: 0.0556 - val_loss: 4.4972 - val_acc: 0.0556\n",
      "3 7\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 37s - loss: 4.6175 - acc: 0.0562 - val_loss: 4.4782 - val_acc: 0.0556\n",
      "3 8\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 37s - loss: 4.6054 - acc: 0.0613 - val_loss: 4.4999 - val_acc: 0.0502\n",
      "3 9\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 37s - loss: 4.7470 - acc: 0.0520 - val_loss: 4.5178 - val_acc: 0.0556\n",
      "4 1\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 38s - loss: 4.6679 - acc: 0.0575 - val_loss: 4.4981 - val_acc: 0.0556\n",
      "4 2\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 38s - loss: 4.6284 - acc: 0.0560 - val_loss: 4.4817 - val_acc: 0.0591\n",
      "4 3\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 38s - loss: 4.6286 - acc: 0.0585 - val_loss: 4.5058 - val_acc: 0.0556\n",
      "4 4\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 38s - loss: 4.6166 - acc: 0.0571 - val_loss: 4.4961 - val_acc: 0.0502\n",
      "4 5\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 40s - loss: 4.6296 - acc: 0.0569 - val_loss: 4.5021 - val_acc: 0.0556\n",
      "4 6\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 38s - loss: 4.6117 - acc: 0.0518 - val_loss: 4.4973 - val_acc: 0.0556\n",
      "4 7\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 40s - loss: 4.6216 - acc: 0.0613 - val_loss: 4.5084 - val_acc: 0.0556\n",
      "4 8\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 39s - loss: 4.6212 - acc: 0.0577 - val_loss: 4.5128 - val_acc: 0.0556\n",
      "4 9\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 39s - loss: 4.7393 - acc: 0.0552 - val_loss: 4.5194 - val_acc: 0.0556\n",
      "5 1\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 39s - loss: 4.6779 - acc: 0.0585 - val_loss: 4.5181 - val_acc: 0.0412\n",
      "5 2\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 40s - loss: 4.6367 - acc: 0.0540 - val_loss: 4.5014 - val_acc: 0.0412\n",
      "5 3\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 40s - loss: 4.6209 - acc: 0.0573 - val_loss: 4.4955 - val_acc: 0.0556\n",
      "5 4\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 43s - loss: 4.6262 - acc: 0.0512 - val_loss: 4.4755 - val_acc: 0.0573\n",
      "5 5\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 41s - loss: 4.6205 - acc: 0.0571 - val_loss: 4.4965 - val_acc: 0.0556\n",
      "5 6\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 41s - loss: 4.6164 - acc: 0.0607 - val_loss: 4.4931 - val_acc: 0.0556\n",
      "5 7\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 41s - loss: 4.6226 - acc: 0.0581 - val_loss: 4.4785 - val_acc: 0.0556\n",
      "5 8\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 41s - loss: 4.6163 - acc: 0.0585 - val_loss: 4.4838 - val_acc: 0.0412\n",
      "5 9\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 41s - loss: 4.7505 - acc: 0.0506 - val_loss: 4.5227 - val_acc: 0.0573\n",
      "6 1\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 42s - loss: 4.6544 - acc: 0.0566 - val_loss: 4.5055 - val_acc: 0.0573\n",
      "6 2\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 44s - loss: 4.6393 - acc: 0.0583 - val_loss: 4.4943 - val_acc: 0.0556\n",
      "6 3\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 42s - loss: 4.6156 - acc: 0.0544 - val_loss: 4.4933 - val_acc: 0.0556\n",
      "6 4\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 42s - loss: 4.6041 - acc: 0.0587 - val_loss: 4.5035 - val_acc: 0.0556\n",
      "6 5\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 43s - loss: 4.6156 - acc: 0.0573 - val_loss: 4.4995 - val_acc: 0.0591\n",
      "6 6\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 43s - loss: 4.5813 - acc: 0.0649 - val_loss: 4.4196 - val_acc: 0.0645\n",
      "6 7\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 43s - loss: 4.6130 - acc: 0.0591 - val_loss: 4.4932 - val_acc: 0.0681\n",
      "6 8\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 44s - loss: 4.6152 - acc: 0.0583 - val_loss: 4.4834 - val_acc: 0.0717\n",
      "6 9\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 43s - loss: 4.7623 - acc: 0.0591 - val_loss: 4.5321 - val_acc: 0.0556\n",
      "7 1\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 44s - loss: 4.6430 - acc: 0.0575 - val_loss: 4.5031 - val_acc: 0.0412\n",
      "7 2\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 44s - loss: 4.6327 - acc: 0.0540 - val_loss: 4.4789 - val_acc: 0.0556\n",
      "7 3\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 44s - loss: 4.6234 - acc: 0.0589 - val_loss: 4.5029 - val_acc: 0.0430\n",
      "7 4\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 44s - loss: 4.6180 - acc: 0.0597 - val_loss: 4.4797 - val_acc: 0.0412\n",
      "7 5\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 47s - loss: 4.6245 - acc: 0.0558 - val_loss: 4.5167 - val_acc: 0.0573\n",
      "7 6\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 45s - loss: 4.6059 - acc: 0.0534 - val_loss: 4.4869 - val_acc: 0.0556\n",
      "7 7\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 46s - loss: 4.6194 - acc: 0.0554 - val_loss: 4.4810 - val_acc: 0.0556\n",
      "7 8\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 46s - loss: 4.6017 - acc: 0.0566 - val_loss: 4.4975 - val_acc: 0.0412\n",
      "7 9\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 45s - loss: 4.7574 - acc: 0.0575 - val_loss: 4.5144 - val_acc: 0.0556\n",
      "8 1\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 46s - loss: 4.6585 - acc: 0.0560 - val_loss: 4.4979 - val_acc: 0.0556\n",
      "8 2\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 46s - loss: 4.6270 - acc: 0.0577 - val_loss: 4.4982 - val_acc: 0.0430\n",
      "8 3\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 47s - loss: 4.6289 - acc: 0.0526 - val_loss: 4.4946 - val_acc: 0.0609\n",
      "8 4\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 47s - loss: 4.6152 - acc: 0.0536 - val_loss: 4.4760 - val_acc: 0.0591\n",
      "8 5\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 47s - loss: 4.6085 - acc: 0.0568 - val_loss: 4.4785 - val_acc: 0.0484\n",
      "8 6\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 48s - loss: 4.6036 - acc: 0.0603 - val_loss: 4.4729 - val_acc: 0.0466\n",
      "8 7\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 47s - loss: 4.6064 - acc: 0.0581 - val_loss: 4.5377 - val_acc: 0.0609\n",
      "8 8\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.209294). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 70s - loss: 4.6116 - acc: 0.0571 - val_loss: 4.5005 - val_acc: 0.0520\n",
      "8 9\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 56s - loss: 4.7468 - acc: 0.0510 - val_loss: 4.5319 - val_acc: 0.0412\n",
      "9 1\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 50s - loss: 4.6669 - acc: 0.0528 - val_loss: 4.5055 - val_acc: 0.0502\n",
      "9 2\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 49s - loss: 4.6385 - acc: 0.0534 - val_loss: 4.4884 - val_acc: 0.0556\n",
      "9 3\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 49s - loss: 4.6163 - acc: 0.0542 - val_loss: 4.4865 - val_acc: 0.0556\n",
      "9 4\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 49s - loss: 4.6210 - acc: 0.0568 - val_loss: 4.4968 - val_acc: 0.0556\n",
      "9 5\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 50s - loss: 4.6197 - acc: 0.0552 - val_loss: 4.4896 - val_acc: 0.0556\n",
      "9 6\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 49s - loss: 4.6063 - acc: 0.0552 - val_loss: 4.4659 - val_acc: 0.0645\n",
      "9 7\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 50s - loss: 4.6259 - acc: 0.0524 - val_loss: 4.5105 - val_acc: 0.0556\n",
      "9 8\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 50s - loss: 4.6103 - acc: 0.0575 - val_loss: 4.4907 - val_acc: 0.0699\n",
      "9 9\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    for j in range(1, 10):\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(size + 1, i, input_length=6))\n",
    "        model.add(LSTM(j))\n",
    "        model.add(Dense(size, activation='softmax'))\n",
    "        model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "        model.fit(train_X, train_y, epochs=1, batch_size=1, verbose=2, validation_data=(test_X, test_y));\n",
    "        print (i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 50s - loss: 4.6158 - acc: 0.0601 - val_loss: 4.4378 - val_acc: 0.0609\n",
      "11 11\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 51s - loss: 4.5862 - acc: 0.0635 - val_loss: 4.3126 - val_acc: 0.0842\n",
      "11 12\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 51s - loss: 4.6004 - acc: 0.0665 - val_loss: 4.3291 - val_acc: 0.0860\n",
      "11 13\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 52s - loss: 4.5700 - acc: 0.0731 - val_loss: 4.3151 - val_acc: 0.0735\n",
      "11 14\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 52s - loss: 4.6072 - acc: 0.0615 - val_loss: 4.3497 - val_acc: 0.0735\n",
      "11 15\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 52s - loss: 4.5691 - acc: 0.0669 - val_loss: 4.2528 - val_acc: 0.0878\n",
      "11 16\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 1216s - loss: 4.6062 - acc: 0.0635 - val_loss: 4.4208 - val_acc: 0.0824\n",
      "11 17\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 58s - loss: 4.5561 - acc: 0.0715 - val_loss: 4.2968 - val_acc: 0.0806\n",
      "11 18\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 58s - loss: 4.5729 - acc: 0.0669 - val_loss: 4.2220 - val_acc: 0.0896\n",
      "11 19\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 54s - loss: 4.5783 - acc: 0.0589 - val_loss: 4.3688 - val_acc: 0.0591\n",
      "12 11\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 54s - loss: 4.6063 - acc: 0.0613 - val_loss: 4.3724 - val_acc: 0.0753\n",
      "12 12\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 54s - loss: 4.5840 - acc: 0.0633 - val_loss: 4.2904 - val_acc: 0.0896\n",
      "12 13\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 55s - loss: 4.6112 - acc: 0.0583 - val_loss: 4.4756 - val_acc: 0.0502\n",
      "12 14\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 54s - loss: 4.6106 - acc: 0.0615 - val_loss: 4.4320 - val_acc: 0.0663\n",
      "12 15\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 54s - loss: 4.5479 - acc: 0.0695 - val_loss: 4.2485 - val_acc: 0.0896\n",
      "12 16\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 55s - loss: 4.6110 - acc: 0.0611 - val_loss: 4.4164 - val_acc: 0.0806\n",
      "12 17\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 55s - loss: 4.5247 - acc: 0.0802 - val_loss: 4.2231 - val_acc: 0.0860\n",
      "12 18\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 56s - loss: 4.6061 - acc: 0.0635 - val_loss: 4.4149 - val_acc: 0.0789\n",
      "12 19\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 56s - loss: 4.5965 - acc: 0.0550 - val_loss: 4.3807 - val_acc: 0.0753\n",
      "13 11\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 55s - loss: 4.6050 - acc: 0.0613 - val_loss: 4.4655 - val_acc: 0.0645\n",
      "13 12\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 55s - loss: 4.6027 - acc: 0.0623 - val_loss: 4.3851 - val_acc: 0.0645\n",
      "13 13\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 56s - loss: 4.5901 - acc: 0.0703 - val_loss: 4.3616 - val_acc: 0.0735\n",
      "13 14\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 56s - loss: 4.5974 - acc: 0.0562 - val_loss: 4.4708 - val_acc: 0.0412\n",
      "13 15\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 57s - loss: 4.6015 - acc: 0.0562 - val_loss: 4.3884 - val_acc: 0.0824\n",
      "13 16\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 57s - loss: 4.6110 - acc: 0.0569 - val_loss: 4.4685 - val_acc: 0.0556\n",
      "13 17\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 57s - loss: 4.5580 - acc: 0.0695 - val_loss: 4.2671 - val_acc: 0.0914\n",
      "13 18\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "for i in range(11, 20):\n",
    "    for j in range(11, 20):\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(size + 1, i, input_length=6))\n",
    "        model.add(LSTM(j))\n",
    "        model.add(Dense(size, activation='softmax'))\n",
    "        model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "        model.fit(train_X, train_y, epochs=1, batch_size=1, verbose=2, validation_data=(test_X, test_y));\n",
    "        print (i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 34s - loss: 4.5627 - acc: 0.0667 - val_loss: 4.2181 - val_acc: 0.0950\n",
      "21 21\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 35s - loss: 4.5260 - acc: 0.0765 - val_loss: 4.1930 - val_acc: 0.1004\n",
      "21 22\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 35s - loss: 4.4857 - acc: 0.0783 - val_loss: 4.1343 - val_acc: 0.0968\n",
      "21 23\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 35s - loss: 4.4851 - acc: 0.0812 - val_loss: 4.1343 - val_acc: 0.0914\n",
      "21 24\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 36s - loss: 4.5822 - acc: 0.0611 - val_loss: 4.3339 - val_acc: 0.0753\n",
      "21 25\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 36s - loss: 4.4736 - acc: 0.0802 - val_loss: 4.1273 - val_acc: 0.0896\n",
      "21 26\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 36s - loss: 4.4976 - acc: 0.0751 - val_loss: 4.1283 - val_acc: 0.0932\n",
      "21 27\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 37s - loss: 4.4882 - acc: 0.0753 - val_loss: 4.1140 - val_acc: 0.0950\n",
      "21 28\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 37s - loss: 4.4105 - acc: 0.0878 - val_loss: 4.0947 - val_acc: 0.0914\n",
      "21 29\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 37s - loss: 4.4720 - acc: 0.0870 - val_loss: 4.1271 - val_acc: 0.0932\n",
      "22 21\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 37s - loss: 4.5704 - acc: 0.0669 - val_loss: 4.2892 - val_acc: 0.0878\n",
      "22 22\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 37s - loss: 4.4496 - acc: 0.0816 - val_loss: 4.0836 - val_acc: 0.1129\n",
      "22 23\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 37s - loss: 4.5078 - acc: 0.0693 - val_loss: 4.1453 - val_acc: 0.0842\n",
      "22 24\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 38s - loss: 4.4769 - acc: 0.0842 - val_loss: 4.0868 - val_acc: 0.1039\n",
      "22 25\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 38s - loss: 4.5156 - acc: 0.0777 - val_loss: 4.1239 - val_acc: 0.0968\n",
      "22 26\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 39s - loss: 4.4534 - acc: 0.0840 - val_loss: 4.1264 - val_acc: 0.0950\n",
      "22 27\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 40s - loss: 4.4494 - acc: 0.0896 - val_loss: 4.0459 - val_acc: 0.0824\n",
      "22 28\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 39s - loss: 4.4957 - acc: 0.0793 - val_loss: 4.1075 - val_acc: 0.0932\n",
      "22 29\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 39s - loss: 4.5106 - acc: 0.0751 - val_loss: 4.1317 - val_acc: 0.0842\n",
      "23 21\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 39s - loss: 4.4230 - acc: 0.0850 - val_loss: 4.1052 - val_acc: 0.0968\n",
      "23 22\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 39s - loss: 4.4744 - acc: 0.0834 - val_loss: 4.1419 - val_acc: 0.0914\n",
      "23 23\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 39s - loss: 4.5248 - acc: 0.0739 - val_loss: 4.1583 - val_acc: 0.0878\n",
      "23 24\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 40s - loss: 4.5212 - acc: 0.0769 - val_loss: 4.1638 - val_acc: 0.1075\n",
      "23 25\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 40s - loss: 4.5118 - acc: 0.0747 - val_loss: 4.1092 - val_acc: 0.1057\n",
      "23 26\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 41s - loss: 4.5378 - acc: 0.0761 - val_loss: 4.1675 - val_acc: 0.0878\n",
      "23 27\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 41s - loss: 4.4287 - acc: 0.0886 - val_loss: 4.0788 - val_acc: 0.1075\n",
      "23 28\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 41s - loss: 4.4193 - acc: 0.0876 - val_loss: 4.0638 - val_acc: 0.1039\n",
      "23 29\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 40s - loss: 4.5049 - acc: 0.0789 - val_loss: 4.1611 - val_acc: 0.0896\n",
      "24 21\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 41s - loss: 4.5176 - acc: 0.0767 - val_loss: 4.2254 - val_acc: 0.1004\n",
      "24 22\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 41s - loss: 4.4936 - acc: 0.0828 - val_loss: 4.1685 - val_acc: 0.0914\n",
      "24 23\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 43s - loss: 4.5014 - acc: 0.0808 - val_loss: 4.0886 - val_acc: 0.1147\n",
      "24 24\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 42s - loss: 4.5364 - acc: 0.0671 - val_loss: 4.1768 - val_acc: 0.0932\n",
      "24 25\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 42s - loss: 4.5156 - acc: 0.0804 - val_loss: 4.1102 - val_acc: 0.0968\n",
      "24 26\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 42s - loss: 4.4794 - acc: 0.0818 - val_loss: 4.1515 - val_acc: 0.0950\n",
      "24 27\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 44s - loss: 4.4762 - acc: 0.0785 - val_loss: 4.1051 - val_acc: 0.0986\n",
      "24 28\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 43s - loss: 4.3731 - acc: 0.0944 - val_loss: 4.0055 - val_acc: 0.1111\n",
      "24 29\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 44s - loss: 4.4795 - acc: 0.0787 - val_loss: 4.1222 - val_acc: 0.0932\n",
      "25 21\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 44s - loss: 4.4707 - acc: 0.0757 - val_loss: 4.1657 - val_acc: 0.0968\n",
      "25 22\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 44s - loss: 4.4974 - acc: 0.0763 - val_loss: 4.1442 - val_acc: 0.0950\n",
      "25 23\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 45s - loss: 4.5118 - acc: 0.0791 - val_loss: 4.1928 - val_acc: 0.0914\n",
      "25 24\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 44s - loss: 4.4425 - acc: 0.0802 - val_loss: 4.0894 - val_acc: 0.0824\n",
      "25 25\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 45s - loss: 4.4298 - acc: 0.0836 - val_loss: 4.0739 - val_acc: 0.0896\n",
      "25 26\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 45s - loss: 4.5692 - acc: 0.0713 - val_loss: 4.2063 - val_acc: 0.1147\n",
      "25 27\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 45s - loss: 4.4332 - acc: 0.0914 - val_loss: 4.1177 - val_acc: 0.1057\n",
      "25 28\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 46s - loss: 4.4010 - acc: 0.0886 - val_loss: 4.0666 - val_acc: 0.1039\n",
      "25 29\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 45s - loss: 4.5480 - acc: 0.0733 - val_loss: 4.2210 - val_acc: 0.0914\n",
      "26 21\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 45s - loss: 4.4888 - acc: 0.0789 - val_loss: 4.1355 - val_acc: 0.1022\n",
      "26 22\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 46s - loss: 4.4594 - acc: 0.0785 - val_loss: 4.1217 - val_acc: 0.0914\n",
      "26 23\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 46s - loss: 4.4176 - acc: 0.0834 - val_loss: 4.0916 - val_acc: 0.1022\n",
      "26 24\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 46s - loss: 4.4359 - acc: 0.0769 - val_loss: 4.0947 - val_acc: 0.0968\n",
      "26 25\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 46s - loss: 4.5371 - acc: 0.0761 - val_loss: 4.1501 - val_acc: 0.0986\n",
      "26 26\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 47s - loss: 4.4646 - acc: 0.0828 - val_loss: 4.1001 - val_acc: 0.1111\n",
      "26 27\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 47s - loss: 4.4524 - acc: 0.0812 - val_loss: 4.0743 - val_acc: 0.0968\n",
      "26 28\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 48s - loss: 4.4387 - acc: 0.0908 - val_loss: 4.0512 - val_acc: 0.1165\n",
      "26 29\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 48s - loss: 4.5023 - acc: 0.0862 - val_loss: 4.2332 - val_acc: 0.0932\n",
      "27 21\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 48s - loss: 4.3998 - acc: 0.0924 - val_loss: 4.1189 - val_acc: 0.0986\n",
      "27 22\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 49s - loss: 4.5279 - acc: 0.0761 - val_loss: 4.1134 - val_acc: 0.1093\n",
      "27 23\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 48s - loss: 4.5174 - acc: 0.0747 - val_loss: 4.1635 - val_acc: 0.0968\n",
      "27 24\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 48s - loss: 4.4518 - acc: 0.0844 - val_loss: 4.0207 - val_acc: 0.1129\n",
      "27 25\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 49s - loss: 4.4852 - acc: 0.0793 - val_loss: 4.0736 - val_acc: 0.1147\n",
      "27 26\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 49s - loss: 4.4580 - acc: 0.0830 - val_loss: 4.0606 - val_acc: 0.1057\n",
      "27 27\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 50s - loss: 4.4850 - acc: 0.0804 - val_loss: 4.0874 - val_acc: 0.0986\n",
      "27 28\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 50s - loss: 4.4075 - acc: 0.0892 - val_loss: 4.0459 - val_acc: 0.1147\n",
      "27 29\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 49s - loss: 4.4495 - acc: 0.0900 - val_loss: 4.0954 - val_acc: 0.0986\n",
      "28 21\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 50s - loss: 4.4357 - acc: 0.0838 - val_loss: 4.1051 - val_acc: 0.0717\n",
      "28 22\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 51s - loss: 4.4869 - acc: 0.0795 - val_loss: 4.1515 - val_acc: 0.0789\n",
      "28 23\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 51s - loss: 4.4184 - acc: 0.0866 - val_loss: 4.0752 - val_acc: 0.1075\n",
      "28 24\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 51s - loss: 4.4719 - acc: 0.0783 - val_loss: 4.0973 - val_acc: 0.1022\n",
      "28 25\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 51s - loss: 4.4710 - acc: 0.0834 - val_loss: 4.0953 - val_acc: 0.0950\n",
      "28 26\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 51s - loss: 4.4219 - acc: 0.0862 - val_loss: 4.0499 - val_acc: 0.1057\n",
      "28 27\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 52s - loss: 4.4462 - acc: 0.0846 - val_loss: 4.0670 - val_acc: 0.0896\n",
      "28 28\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 51s - loss: 4.4471 - acc: 0.0870 - val_loss: 4.0643 - val_acc: 0.0950\n",
      "28 29\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 52s - loss: 4.5051 - acc: 0.0872 - val_loss: 4.1191 - val_acc: 0.1093\n",
      "29 21\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 184s - loss: 4.5309 - acc: 0.0703 - val_loss: 4.1672 - val_acc: 0.0771\n",
      "29 22\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 53s - loss: 4.4972 - acc: 0.0791 - val_loss: 4.1130 - val_acc: 0.0878\n",
      "29 23\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 53s - loss: 4.4594 - acc: 0.0824 - val_loss: 4.0788 - val_acc: 0.1093\n",
      "29 24\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 54s - loss: 4.4739 - acc: 0.0783 - val_loss: 4.1222 - val_acc: 0.1022\n",
      "29 25\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 54s - loss: 4.4211 - acc: 0.0888 - val_loss: 4.0841 - val_acc: 0.0878\n",
      "29 26\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 54s - loss: 4.4239 - acc: 0.0856 - val_loss: 4.0749 - val_acc: 0.1004\n",
      "29 27\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 54s - loss: 4.4364 - acc: 0.0888 - val_loss: 4.0602 - val_acc: 0.0932\n",
      "29 28\n",
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      " - 55s - loss: 4.4217 - acc: 0.0844 - val_loss: 4.0566 - val_acc: 0.0986\n",
      "29 29\n"
     ]
    }
   ],
   "source": [
    "for i in range(21, 30):\n",
    "    for j in range(21, 30):\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(size + 1, i, input_length=6))\n",
    "        model.add(LSTM(j))\n",
    "        model.add(Dense(size, activation='softmax'))\n",
    "        model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "        model.fit(train_X, train_y, epochs=1, batch_size=1, verbose=2, validation_data=(test_X, test_y));\n",
    "        print (i, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем параметры 26 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5022 samples, validate on 558 samples\n",
      "Epoch 1/40\n",
      " - 90s - loss: 4.4730 - acc: 0.0822 - val_loss: 4.0199 - val_acc: 0.1219\n",
      "Epoch 2/40\n",
      " - 43s - loss: 3.8688 - acc: 0.1493 - val_loss: 3.7847 - val_acc: 0.1272\n",
      "Epoch 3/40\n",
      " - 42s - loss: 3.6276 - acc: 0.1840 - val_loss: 3.6457 - val_acc: 0.1846\n",
      "Epoch 4/40\n",
      " - 42s - loss: 3.4441 - acc: 0.2168 - val_loss: 3.5897 - val_acc: 0.1667\n",
      "Epoch 5/40\n",
      " - 46s - loss: 3.2902 - acc: 0.2429 - val_loss: 3.4776 - val_acc: 0.2115\n",
      "Epoch 6/40\n",
      " - 43s - loss: 3.1563 - acc: 0.2577 - val_loss: 3.4261 - val_acc: 0.2419\n",
      "Epoch 7/40\n",
      " - 42s - loss: 3.0314 - acc: 0.2772 - val_loss: 3.3628 - val_acc: 0.2348\n",
      "Epoch 8/40\n",
      " - 43s - loss: 2.9171 - acc: 0.2937 - val_loss: 3.3831 - val_acc: 0.2491\n",
      "Epoch 9/40\n",
      " - 44s - loss: 2.8143 - acc: 0.3134 - val_loss: 3.3392 - val_acc: 0.2581\n",
      "Epoch 10/40\n",
      " - 46s - loss: 2.7171 - acc: 0.3317 - val_loss: 3.3282 - val_acc: 0.2652\n",
      "Epoch 11/40\n",
      " - 46s - loss: 2.6201 - acc: 0.3584 - val_loss: 3.3273 - val_acc: 0.2634\n",
      "Epoch 12/40\n",
      " - 47s - loss: 2.5382 - acc: 0.3634 - val_loss: 3.3479 - val_acc: 0.2724\n",
      "Epoch 13/40\n",
      " - 47s - loss: 2.4509 - acc: 0.3879 - val_loss: 3.3593 - val_acc: 0.2652\n",
      "Epoch 14/40\n",
      " - 44s - loss: 2.3720 - acc: 0.4008 - val_loss: 3.3687 - val_acc: 0.2616\n",
      "Epoch 15/40\n",
      " - 45s - loss: 2.2945 - acc: 0.4158 - val_loss: 3.3518 - val_acc: 0.2849\n",
      "Epoch 16/40\n",
      " - 45s - loss: 2.2253 - acc: 0.4323 - val_loss: 3.3617 - val_acc: 0.2724\n",
      "Epoch 17/40\n",
      " - 46s - loss: 2.1592 - acc: 0.4446 - val_loss: 3.3822 - val_acc: 0.2670\n",
      "Epoch 18/40\n",
      " - 44s - loss: 2.0888 - acc: 0.4659 - val_loss: 3.3806 - val_acc: 0.2921\n",
      "Epoch 19/40\n",
      " - 46s - loss: 2.0214 - acc: 0.4765 - val_loss: 3.4377 - val_acc: 0.2724\n",
      "Epoch 20/40\n",
      " - 45s - loss: 1.9570 - acc: 0.4956 - val_loss: 3.4437 - val_acc: 0.2849\n",
      "Epoch 21/40\n",
      " - 50s - loss: 1.8976 - acc: 0.5076 - val_loss: 3.4608 - val_acc: 0.2796\n",
      "Epoch 22/40\n",
      " - 49s - loss: 1.8341 - acc: 0.5283 - val_loss: 3.4875 - val_acc: 0.2867\n",
      "Epoch 23/40\n",
      " - 48s - loss: 1.7752 - acc: 0.5414 - val_loss: 3.5027 - val_acc: 0.2885\n",
      "Epoch 24/40\n",
      " - 47s - loss: 1.7167 - acc: 0.5599 - val_loss: 3.5516 - val_acc: 0.2832\n",
      "Epoch 25/40\n",
      " - 46s - loss: 1.6590 - acc: 0.5741 - val_loss: 3.5830 - val_acc: 0.2975\n",
      "Epoch 26/40\n",
      " - 45s - loss: 1.6138 - acc: 0.5785 - val_loss: 3.6331 - val_acc: 0.2939\n",
      "Epoch 27/40\n",
      " - 47s - loss: 1.5620 - acc: 0.5958 - val_loss: 3.6467 - val_acc: 0.2903\n",
      "Epoch 28/40\n",
      " - 46s - loss: 1.5135 - acc: 0.6151 - val_loss: 3.6446 - val_acc: 0.2903\n",
      "Epoch 29/40\n",
      " - 44s - loss: 1.4663 - acc: 0.6223 - val_loss: 3.6771 - val_acc: 0.2903\n",
      "Epoch 30/40\n",
      " - 42s - loss: 1.4261 - acc: 0.6344 - val_loss: 3.7350 - val_acc: 0.2885\n",
      "Epoch 31/40\n",
      " - 43s - loss: 1.3782 - acc: 0.6476 - val_loss: 3.7065 - val_acc: 0.2885\n",
      "Epoch 32/40\n",
      " - 44s - loss: 1.3355 - acc: 0.6611 - val_loss: 3.7545 - val_acc: 0.3082\n",
      "Epoch 33/40\n",
      " - 52s - loss: 1.2975 - acc: 0.6716 - val_loss: 3.7994 - val_acc: 0.3047\n",
      "Epoch 34/40\n",
      " - 48s - loss: 1.2632 - acc: 0.6742 - val_loss: 3.8126 - val_acc: 0.3262\n",
      "Epoch 35/40\n",
      " - 49s - loss: 1.2209 - acc: 0.6906 - val_loss: 3.8759 - val_acc: 0.3065\n",
      "Epoch 36/40\n",
      " - 46s - loss: 1.1930 - acc: 0.7001 - val_loss: 3.8897 - val_acc: 0.3100\n",
      "Epoch 37/40\n",
      " - 46s - loss: 1.1535 - acc: 0.7063 - val_loss: 3.8896 - val_acc: 0.3315\n",
      "Epoch 38/40\n",
      " - 45s - loss: 1.1215 - acc: 0.7164 - val_loss: 3.9530 - val_acc: 0.3190\n",
      "Epoch 39/40\n",
      " - 45s - loss: 1.1016 - acc: 0.7153 - val_loss: 3.9906 - val_acc: 0.3029\n",
      "Epoch 40/40\n",
      " - 46s - loss: 1.0633 - acc: 0.7264 - val_loss: 4.0060 - val_acc: 0.3100\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(size + 1, 26, input_length=6))\n",
    "model.add(LSTM(29))\n",
    "model.add(Dense(size, activation='softmax'))\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(train_X, train_y, epochs=40, batch_size=1, verbose=2, validation_data=(test_X, test_y));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotLearning(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.acc = []\n",
    "        self.val_acc = []\n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.acc.append(logs.get('acc'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        self.i += 1\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        ax1.set_yscale('log')\n",
    "        ax1.plot(self.x, self.losses, label=\"loss\")\n",
    "        ax1.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        ax1.legend()\n",
    "        \n",
    "        ax2.plot(self.x, self.acc, label=\"accuracy\")\n",
    "        ax2.plot(self.x, self.val_acc, label=\"validation accuracy\")\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.show();\n",
    "        \n",
    "plot = PlotLearning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff669ccf128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(size + 1, 26, input_length=6))\n",
    "model.add(LSTM(29))\n",
    "model.add(Dense(size, activation='softmax'))\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(train_X, train_y, epochs=5, batch_size=1, validation_data=(test_X, test_y), callbacks=[plot]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
