{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import ml.structures\n",
    "import ml.dataset.corpus as corpus\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.engine.topology import Input\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.layers import Concatenate, Merge\n",
    "\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_16(chord):\n",
    "    c = 16 / (128 / chord.duration)\n",
    "    array = np.array([note.number for note in chord.notes])\n",
    "    if len(array) == 0:\n",
    "        array = [0]\n",
    "    if c >= 1:\n",
    "        return 1, np.tile(array, (int(c), 1))\n",
    "    else:\n",
    "        return 0, [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_song(song, notes, chords):\n",
    "    chords_track = []\n",
    "    notes_track = np.array([])\n",
    "    flag = 0\n",
    "    for note in song.tracks[0].chords:\n",
    "        if (make_16(note)[0] == 0):\n",
    "            flag = 1\n",
    "        notes_track = np.append(notes_track, make_16(note)[1])\n",
    "    for chord in song.tracks[1].chords:\n",
    "        if (make_16(chord)[0] == 0):\n",
    "            flag = 1\n",
    "        chords_track.append(make_16(chord)[1])\n",
    "    if flag == 1:\n",
    "        return 0, notes, chords\n",
    "    return 1, notes_track, chords_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_array(X, size):\n",
    "    for j in range(len(X)):\n",
    "        array = np.zeros(size-len(X[j])) - 1\n",
    "        X[j] = np.array(X[j])\n",
    "        X[j] = np.append(X[j], array)\n",
    "    X = np.array(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X_Y(chords):\n",
    "    real_chords = []\n",
    "    y = []\n",
    "    for i, subchord in enumerate(chords):\n",
    "        if i != len(chords) - 1:\n",
    "            for ssubchord in subchord:\n",
    "                real_chords.append(ssubchord)\n",
    "            size = len(subchord)\n",
    "            for j in range(size):\n",
    "                y.append(chords[i+1][-1])\n",
    "    return real_chords, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def notes_to_np(notes):\n",
    "    for i in range(len(notes)):\n",
    "        notes[i] = np.array(notes[i])\n",
    "    notes = np.array(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unique_chords(X, unique_chords):\n",
    "    for x in X:\n",
    "        unique_chords = np.append(unique_chords, np.array(x))\n",
    "    return unique_chords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_coded(X):\n",
    "    return np.zeros(len(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(X, coded_X):\n",
    "    for j, k in enumerate(X):\n",
    "        for i, unique_chord in enumerate(unique_chords):\n",
    "            if np.array_equal(k, unique_chord):\n",
    "                coded_X[j] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:7: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "446/446 [==============================] - 7s 15ms/step - loss: 4.5225 - acc: 0.1794\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 4s 15ms/step - loss: 2.5222 - acc: 0.1783\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 1s 13ms/step - loss: 3.2636 - acc: 0.0222\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 1s 12ms/step - loss: 2.5649 - acc: 0.2444\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 5.8455 - acc: 0.0957\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 4.3357 - acc: 0.3830\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 2s 14ms/step - loss: 6.1361 - acc: 0.1404\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 1s 15ms/step - loss: 4.9685 - acc: 0.1277\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 3.4739 - acc: 0.2553\n",
      "Epoch 1/1\n",
      "644/644 [==============================] - 9s 14ms/step - loss: 6.5475 - acc: 0.0295\n",
      "Epoch 1/1\n",
      "516/516 [==============================] - 7s 13ms/step - loss: 4.6237 - acc: 0.0504\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 6.0902 - acc: 0.0981\n",
      "Epoch 1/1\n",
      "476/476 [==============================] - 6s 12ms/step - loss: 3.9524 - acc: 0.2143\n",
      "Epoch 1/1\n",
      "126/126 [==============================] - 1s 12ms/step - loss: 8.7996 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 7.2150 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 3s 15ms/step - loss: 7.1574 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 3s 14ms/step - loss: 2.0544 - acc: 0.3288\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 1.3317 - acc: 0.6170\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 2s 13ms/step - loss: 3.4887 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "318/318 [==============================] - 4s 13ms/step - loss: 6.0708 - acc: 0.0503\n",
      "Epoch 1/1\n",
      "254/254 [==============================] - 3s 13ms/step - loss: 6.1219 - acc: 0.0787\n",
      "Epoch 1/1\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 5.8700 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 5.7490 - acc: 0.0532\n",
      "Epoch 1/1\n",
      "310/310 [==============================] - 4s 14ms/step - loss: 3.9666 - acc: 0.2226\n",
      "Epoch 1/1\n",
      "950/950 [==============================] - 13s 13ms/step - loss: 2.2528 - acc: 0.3263\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 6.7042 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "126/126 [==============================] - 1s 12ms/step - loss: 5.4475 - acc: 0.0635\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 1s 13ms/step - loss: 3.7292 - acc: 0.2872\n",
      "Epoch 1/1\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 3.6150 - acc: 0.2143\n",
      "Epoch 1/1\n",
      "446/446 [==============================] - 6s 14ms/step - loss: 5.2733 - acc: 0.0852\n",
      "Epoch 1/1\n",
      "254/254 [==============================] - 3s 12ms/step - loss: 7.1496 - acc: 0.0157\n",
      "Epoch 1/1\n",
      "254/254 [==============================] - 3s 12ms/step - loss: 5.8676 - acc: 0.1417\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 4s 14ms/step - loss: 5.3061 - acc: 0.1503\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 4s 13ms/step - loss: 2.6826 - acc: 0.3601\n",
      "Epoch 1/1\n",
      "382/382 [==============================] - 5s 13ms/step - loss: 1.9553 - acc: 0.4921\n",
      "Epoch 1/1\n",
      "2044/2044 [==============================] - 26s 13ms/step - loss: 4.8817 - acc: 0.0793\n",
      "Epoch 1/1\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 7.6833 - acc: 0.0079\n",
      "Epoch 1/1\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 5.1351 - acc: 0.1111\n",
      "Epoch 1/1\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 3.1012 - acc: 0.2540\n",
      "Epoch 1/1\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 2.3562 - acc: 0.3016\n",
      "Epoch 1/1\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 4.0251 - acc: 0.2955\n",
      "Epoch 1/1\n",
      "1822/1822 [==============================] - 24s 13ms/step - loss: 1.0835 - acc: 0.5823\n",
      "Epoch 1/1\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 7.3011 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 5.5638 - acc: 0.5417\n",
      "Epoch 1/1\n",
      "382/382 [==============================] - 5s 13ms/step - loss: 5.1854 - acc: 0.0026\n",
      "Epoch 1/1\n",
      "254/254 [==============================] - 3s 13ms/step - loss: 2.7615 - acc: 0.2008\n",
      "Epoch 1/1\n",
      "350/350 [==============================] - 5s 13ms/step - loss: 8.3378 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "446/446 [==============================] - 6s 13ms/step - loss: 6.5457 - acc: 0.0224\n",
      "Epoch 1/1\n",
      "702/702 [==============================] - 9s 13ms/step - loss: 6.3542 - acc: 0.0556\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 1s 14ms/step - loss: 8.9617 - acc: 0.0213\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 2s 13ms/step - loss: 8.1983 - acc: 0.0105\n",
      "Epoch 1/1\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 10.9882 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 3s 13ms/step - loss: 6.3970 - acc: 0.1984\n",
      "Epoch 1/1\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 5.8084 - acc: 0.0909\n",
      "Epoch 1/1\n",
      "638/638 [==============================] - 8s 13ms/step - loss: 3.7014 - acc: 0.3401\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 3s 13ms/step - loss: 2.5850 - acc: 0.4385\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 2s 12ms/step - loss: 7.6200 - acc: 0.0198\n",
      "Epoch 1/1\n",
      "394/394 [==============================] - 5s 13ms/step - loss: 3.8910 - acc: 0.1878\n",
      "Epoch 1/1\n",
      "40/40 [==============================] - 1s 13ms/step - loss: 10.9150 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "40/40 [==============================] - 0s 12ms/step - loss: 8.8505 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 4s 13ms/step - loss: 6.9318 - acc: 0.2230\n",
      "Epoch 1/1\n",
      "360/360 [==============================] - 5s 13ms/step - loss: 4.9329 - acc: 0.2222\n",
      "Epoch 1/1\n",
      "382/382 [==============================] - 5s 13ms/step - loss: 6.3964 - acc: 0.0995\n",
      "Epoch 1/1\n",
      "382/382 [==============================] - 5s 13ms/step - loss: 4.5501 - acc: 0.2853\n",
      "Epoch 1/1\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 11.5317 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "618/618 [==============================] - 8s 13ms/step - loss: 6.9231 - acc: 0.0809\n",
      "Epoch 1/1\n",
      "318/318 [==============================] - 4s 12ms/step - loss: 6.2959 - acc: 0.1792\n",
      "Epoch 1/1\n",
      "208/208 [==============================] - 3s 13ms/step - loss: 6.7147 - acc: 0.0433\n",
      "Epoch 1/1\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 9.3359 - acc: 0.0556\n",
      "Epoch 1/1\n",
      "254/254 [==============================] - 3s 13ms/step - loss: 4.2373 - acc: 0.2913\n",
      "Epoch 1/1\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 8.0427 - acc: 0.0968\n",
      "Epoch 1/1\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 10.0744 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 1s 13ms/step - loss: 9.8425 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "702/702 [==============================] - 9s 13ms/step - loss: 6.6333 - acc: 0.0741\n",
      "Epoch 1/1\n",
      "338/338 [==============================] - 4s 13ms/step - loss: 6.9345 - acc: 0.1006\n",
      "Epoch 1/1\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 15.5877 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 3.8065 - acc: 0.1351\n",
      "Epoch 1/1\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 8.2980 - acc: 0.1111\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 4s 13ms/step - loss: 5.6729 - acc: 0.1556\n",
      "Epoch 1/1\n",
      "254/254 [==============================] - 3s 13ms/step - loss: 8.5088 - acc: 0.1890\n",
      "Epoch 1/1\n",
      "102/102 [==============================] - 1s 13ms/step - loss: 6.3644 - acc: 0.3529\n",
      "Epoch 1/1\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 13.6481 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 2s 13ms/step - loss: 9.8485 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "382/382 [==============================] - 5s 13ms/step - loss: 5.8320 - acc: 0.1099\n",
      "Epoch 1/1\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 2.3758 - acc: 0.4760\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 3s 14ms/step - loss: 4.5055 - acc: 0.1614\n",
      "Epoch 1/1\n",
      "60/60 [==============================] - 1s 13ms/step - loss: 12.2178 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 7.7393 - acc: 0.0547\n",
      "Epoch 1/1\n",
      "240/240 [==============================] - 3s 13ms/step - loss: 6.4391 - acc: 0.1333\n",
      "Epoch 1/1\n",
      "116/116 [==============================] - 1s 13ms/step - loss: 3.7995 - acc: 0.3879\n",
      "Epoch 1/1\n",
      "302/302 [==============================] - 4s 13ms/step - loss: 2.6579 - acc: 0.3543\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 3s 13ms/step - loss: 1.7270 - acc: 0.4769\n",
      "Epoch 1/1\n",
      "134/134 [==============================] - 2s 12ms/step - loss: 10.5038 - acc: 0.0075\n",
      "Epoch 1/1\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 9.8179 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "254/254 [==============================] - 3s 12ms/step - loss: 10.5293 - acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "model_chords = Sequential()\n",
    "model_notes = Sequential()\n",
    "\n",
    "model_chords.add(Embedding(10000, 20, input_length=1, batch_input_shape=(1,1)))\n",
    "model_notes.add(Embedding(128, 20, input_length=1, batch_input_shape=(1,1)))\n",
    "merged_model = Sequential()\n",
    "merged_model.add(Merge([model_chords, model_notes], mode=\"concat\"))\n",
    "merged_model.add(LSTM(20, stateful=True))\n",
    "merged_model.add(Dense(10000, activation='softmax'))\n",
    "merged_model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "unique_chords = np.array([])\n",
    "\n",
    "with open('gtp_dataset_final.pickle', 'rb') as input_file:\n",
    "    i = 0\n",
    "    while True:\n",
    "        try:\n",
    "            i += 1\n",
    "            song = ml.structures.Song()\n",
    "            song.undump(input_file)\n",
    "            chords = []\n",
    "            notes = []\n",
    "            flag_notes_chords = cut_song(song, notes, chords)\n",
    "            if (flag_notes_chords[0] == 0) :\n",
    "                continue\n",
    "            notes = flag_notes_chords[1]\n",
    "            chords = flag_notes_chords[2]\n",
    "            X = []\n",
    "            Y = []\n",
    "            X, Y = create_X_Y(chords)\n",
    "            X = norm_array(X, 15)\n",
    "            Y = norm_array(Y, 15)\n",
    "            notes_to_np(notes)\n",
    "            unique_chords = create_unique_chords(X, unique_chords)\n",
    "            unique_chords = create_unique_chords(Y, unique_chords)\n",
    "            unique_chords = unique_chords.reshape((-1, 15))\n",
    "            unique_chords = np.unique(unique_chords, axis=0)\n",
    "            unique_chords = list(unique_chords)\n",
    "            coded_X = []\n",
    "            coded_Y = []\n",
    "            coded_X = create_coded(X)\n",
    "            coded_Y = create_coded(Y)\n",
    "            encode(X, coded_X)\n",
    "            encode(Y, coded_Y)\n",
    "            X = np.array(coded_X)\n",
    "            y = np.array(coded_Y)\n",
    "            X_notes = notes\n",
    "            X_notes = X_notes[:len(X)]\n",
    "            X = X[:len(X_notes)]\n",
    "            y = y[:len(X)]\n",
    "            if (i < 100):\n",
    "                merged_model.fit([X, X_notes], y, epochs=1, batch_size=1, verbose=1)\n",
    "                merged_model.reset_states()\n",
    "            else:\n",
    "                break\n",
    "                merged_model.predict([X, X_notes], batch_size=1, verbose=1)\n",
    "            \n",
    "            \n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(unique_chords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"vocab.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(\"vocab.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.values.T[1:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., -1., -1., ..., -1., -1., -1.],\n",
       "       [25., 49., -1., ..., -1., -1., -1.],\n",
       "       [25., 61., -1., ..., -1., -1., -1.],\n",
       "       ...,\n",
       "       [75., 54., 61., ..., -1., -1., -1.],\n",
       "       [76., 49., -1., ..., -1., -1., -1.],\n",
       "       [76., 61., -1., ..., -1., -1., -1.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model.save(\"NN_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
