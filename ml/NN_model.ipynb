{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mido\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/37/96da8908dd6b04fec9b3d3931fa38c43d36b6942f206d9586efede105e7d/mido-1.2.8-py2.py3-none-any.whl (70kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 1.0MB/s ta 0:00:01    43% |██████████████                  | 30kB 753kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: mido\n",
      "Successfully installed mido-1.2.8\n",
      "\u001b[33mYou are using pip version 10.0.0, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/gpu_venv/lib/python3.4/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/root/gpu_venv/lib64/python3.4/importlib/_bootstrap.py:321: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import sys\n",
    "sys.path.append(\"/root/test/accompaniator\")\n",
    "!pip install mido\n",
    "import ml.structures\n",
    "import ml.dataset.corpus as corpus\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.engine.topology import Input\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.layers import concatenate, Merge\n",
    "from keras.layers.merge import Concatenate\n",
    "\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_16(chord):\n",
    "    if (chord.duration > 0):\n",
    "        c = 16 / (128 / chord.duration)\n",
    "    else:\n",
    "        return 0, [0]\n",
    "    pre_array = np.array([note.number % 12 for note in chord.notes])\n",
    "    array = set()\n",
    "    for el in pre_array:\n",
    "        array.add(el)\n",
    "        if len(array) == 4:\n",
    "            break\n",
    "    array = np.array(list(array))\n",
    "    array = np.sort(array)\n",
    "    if len(array) == 0:\n",
    "        array = [0]\n",
    "    if c >= 1:\n",
    "        return 1, np.tile(array, (int(c), 1))\n",
    "    else:\n",
    "        return 0, [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_song(song, notes, chords):\n",
    "    chords_track = []\n",
    "    notes_track = np.array([])\n",
    "    flag = 0\n",
    "    for note in song.tracks[0].chords:\n",
    "        if (make_16(note)[0] == 0):\n",
    "            flag = 1\n",
    "        notes_track = np.append(notes_track, make_16(note)[1])\n",
    "    for chord in song.tracks[1].chords:\n",
    "        if (make_16(chord)[0] == 0):\n",
    "            flag = 1\n",
    "        chords_track.append(make_16(chord)[1])\n",
    "    if flag == 1:\n",
    "        return 0, notes, chords\n",
    "    return 1, notes_track, chords_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_array(X, size):\n",
    "    for j in range(len(X)):\n",
    "        X[j] = np.unique(np.array(X[j]))[:size]\n",
    "        array = np.zeros(size-len(X[j])) - 1\n",
    "        X[j] = np.append(X[j], array)\n",
    "    X = np.array(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X_Y(chords):\n",
    "    real_chords = []\n",
    "    y = []\n",
    "    for i, subchord in enumerate(chords):\n",
    "        if i != len(chords) - 1:\n",
    "            for ssubchord in subchord:\n",
    "                real_chords.append(ssubchord)\n",
    "            size = len(subchord)\n",
    "            for j in range(size):\n",
    "                y.append(chords[i+1][-1])\n",
    "    return real_chords, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def notes_to_np(notes):\n",
    "    for i in range(len(notes)):\n",
    "        notes[i] = np.array(notes[i])\n",
    "    notes = np.array(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unique_chords(X, unique_chords):\n",
    "    for x in X:\n",
    "        unique_chords = np.append(unique_chords, np.array(x))\n",
    "    return unique_chords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_coded(X):\n",
    "    return np.zeros(len(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(X, coded_X):\n",
    "    for j, k in enumerate(X):\n",
    "        for i, unique_chord in enumerate(unique_chords):\n",
    "            if np.array_equal(k, unique_chord):\n",
    "                coded_X[j] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/gpu_venv/lib/python3.4/site-packages/ipykernel_launcher.py:8: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "446/446 [==============================] - 8s 19ms/step - loss: 3.3185 - acc: 0.1749\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 4s 16ms/step - loss: 2.2006 - acc: 0.1399\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 1s 15ms/step - loss: 6.0876 - acc: 0.1778\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 4.1687 - acc: 0.1778\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 1s 16ms/step - loss: 3.5374 - acc: 0.0745\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 1s 16ms/step - loss: 2.7778 - acc: 0.3830\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 2s 16ms/step - loss: 4.1268 - acc: 0.2982\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 1s 15ms/step - loss: 3.2771 - acc: 0.3830\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 1s 15ms/step - loss: 2.7495 - acc: 0.3830\n",
      "Epoch 1/1\n",
      "644/644 [==============================] - 10s 16ms/step - loss: 4.0503 - acc: 0.0543\n",
      "Epoch 1/1\n",
      "516/516 [==============================] - 8s 16ms/step - loss: 3.4227 - acc: 0.1415\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 2.8649 - acc: 0.1262\n",
      "Epoch 1/1\n",
      "476/476 [==============================] - 4s 8ms/step - loss: 4.1542 - acc: 0.1429\n",
      "Epoch 1/1\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 4.9865 - acc: 0.0794\n",
      "Epoch 1/1\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 3.6128 - acc: 0.2063\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 2s 8ms/step - loss: 4.6954 - acc: 0.1895\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 2s 8ms/step - loss: 2.6695 - acc: 0.3288\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 1s 7ms/step - loss: 1.0417 - acc: 0.7128\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 2s 11ms/step - loss: 1.4298 - acc: 0.6158\n",
      "Epoch 1/1\n",
      "318/318 [==============================] - 5s 15ms/step - loss: 4.3558 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "254/254 [==============================] - 4s 16ms/step - loss: 3.4106 - acc: 0.2362\n",
      "Epoch 1/1\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 4.5062 - acc: 0.1587\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 1s 15ms/step - loss: 3.3271 - acc: 0.0532\n",
      "Epoch 1/1\n",
      "310/310 [==============================] - 5s 16ms/step - loss: 1.8061 - acc: 0.6194\n",
      "Epoch 1/1\n",
      "950/950 [==============================] - 15s 16ms/step - loss: 3.6403 - acc: 0.2295\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 1s 16ms/step - loss: 4.1355 - acc: 0.1702\n",
      "Epoch 1/1\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 4.3747 - acc: 0.2619\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 1s 16ms/step - loss: 2.2690 - acc: 0.4255\n",
      "Epoch 1/1\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 2.8782 - acc: 0.3492\n",
      "Epoch 1/1\n",
      "446/446 [==============================] - 5s 12ms/step - loss: 4.1482 - acc: 0.1031\n",
      "Epoch 1/1\n",
      "254/254 [==============================] - 4s 15ms/step - loss: 3.6834 - acc: 0.2205\n",
      "Epoch 1/1\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 4.0955 - acc: 0.2756\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 4s 13ms/step - loss: 3.2548 - acc: 0.2517\n",
      "Epoch 1/1\n",
      "286/286 [==============================] - 4s 16ms/step - loss: 1.9955 - acc: 0.4126\n",
      "Epoch 1/1\n",
      "382/382 [==============================] - 6s 16ms/step - loss: 1.3683 - acc: 0.5942\n",
      "Epoch 1/1\n",
      "2044/2044 [==============================] - 29s 14ms/step - loss: 3.1281 - acc: 0.2275\n",
      "Epoch 1/1\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 6.7448 - acc: 0.0238\n",
      "Epoch 1/1\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 4.4169 - acc: 0.1032\n",
      "Epoch 1/1\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 2.8912 - acc: 0.2460\n",
      "Epoch 1/1\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 2.1539 - acc: 0.2778\n",
      "Epoch 1/1\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 5.8461 - acc: 0.1591\n",
      "Epoch 1/1\n",
      "1822/1822 [==============================] - 26s 14ms/step - loss: 1.2951 - acc: 0.5659\n",
      "Epoch 1/1\n",
      "48/48 [==============================] - 1s 16ms/step - loss: 7.1655 - acc: 0.0417\n",
      "Epoch 1/1\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 3.3946 - acc: 0.6250\n",
      "Epoch 1/1\n",
      "382/382 [==============================] - 6s 16ms/step - loss: 3.8140 - acc: 0.1937\n",
      "Epoch 1/1\n",
      "254/254 [==============================] - 4s 15ms/step - loss: 2.6323 - acc: 0.2756\n",
      "Epoch 1/1\n",
      "350/350 [==============================] - 5s 15ms/step - loss: 5.1134 - acc: 0.1114\n",
      "Epoch 1/1\n",
      "446/446 [==============================] - 5s 12ms/step - loss: 4.1923 - acc: 0.1861\n",
      "Epoch 1/1\n",
      "702/702 [==============================] - 11s 15ms/step - loss: 3.6032 - acc: 0.2393\n",
      "Epoch 1/1\n",
      "94/94 [==============================] - 1s 15ms/step - loss: 6.6237 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "190/190 [==============================] - 3s 16ms/step - loss: 4.3710 - acc: 0.1895\n",
      "Epoch 1/1\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 10.6238 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 4s 16ms/step - loss: 5.8072 - acc: 0.0516\n",
      "Epoch 1/1\n",
      "110/110 [==============================] - 2s 16ms/step - loss: 4.6683 - acc: 0.2818\n",
      "Epoch 1/1\n",
      "638/638 [==============================] - 10s 16ms/step - loss: 2.2107 - acc: 0.3950\n",
      "Epoch 1/1\n",
      "260/260 [==============================] - 4s 16ms/step - loss: 2.1354 - acc: 0.4808\n",
      "Epoch 1/1\n",
      "202/202 [==============================] - 2s 11ms/step - loss: 6.7461 - acc: 0.0545\n",
      "Epoch 1/1\n",
      "394/394 [==============================] - 5s 13ms/step - loss: 3.2282 - acc: 0.3299\n",
      "Epoch 1/1\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 5.8433 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 4.1261 - acc: 0.3500\n",
      "Epoch 1/1\n",
      "296/296 [==============================] - 3s 9ms/step - loss: 2.7250 - acc: 0.4628\n",
      "Epoch 1/1\n",
      "360/360 [==============================] - 6s 16ms/step - loss: 1.6678 - acc: 0.6139\n",
      "Epoch 1/1\n",
      "382/382 [==============================] - 6s 16ms/step - loss: 2.3007 - acc: 0.3403\n",
      "Epoch 1/1\n",
      "382/382 [==============================] - 6s 16ms/step - loss: 4.7466 - acc: 0.2251\n",
      "Epoch 1/1\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 7.1318 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "618/618 [==============================] - 10s 16ms/step - loss: 4.8110 - acc: 0.0939\n",
      "Epoch 1/1\n",
      "318/318 [==============================] - 5s 16ms/step - loss: 4.8279 - acc: 0.3145\n",
      "Epoch 1/1\n",
      "208/208 [==============================] - 2s 11ms/step - loss: 4.0313 - acc: 0.2740\n",
      "Epoch 1/1\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 4.1892 - acc: 0.1587\n",
      "Epoch 1/1\n",
      "254/254 [==============================] - 3s 13ms/step - loss: 2.9734 - acc: 0.3740\n",
      "Epoch 1/1\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 5.2317 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 7.8850 - acc: 0.0317\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 1s 16ms/step - loss: 7.8686 - acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "model_chords = Sequential()\n",
    "model_notes = Sequential()\n",
    "\n",
    "model_chords.add(Embedding(794, 20, input_length=1, batch_input_shape=(1,1)))\n",
    "model_notes.add(Embedding(128, 20, input_length=1, batch_input_shape=(1,1)))\n",
    "\n",
    "merged_model = Sequential()\n",
    "merged = Merge([model_chords, model_notes])\n",
    "merged_model.add(merged)\n",
    "merged_model.add(LSTM(20, stateful=True))\n",
    "merged_model.add(Dense(794, activation='softmax'))\n",
    "merged_model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "y_real = []\n",
    "y_pred = []\n",
    "unique_chords = np.zeros(4) - 1\n",
    "\n",
    "with open('gtp_dataset_final.pickle', 'rb') as input_file:\n",
    "    i = 0\n",
    "    while True:\n",
    "        try:\n",
    "            i += 1\n",
    "            song = ml.structures.Song()\n",
    "            song.undump(input_file)\n",
    "            chords = []\n",
    "            notes = []\n",
    "            flag_notes_chords = cut_song(song, notes, chords)\n",
    "            if (flag_notes_chords[0] == 0) :\n",
    "                continue\n",
    "            notes = flag_notes_chords[1]\n",
    "            chords = flag_notes_chords[2]\n",
    "            X = []\n",
    "            Y = []\n",
    "            X, Y = create_X_Y(chords)\n",
    "            X = norm_array(X, 4)\n",
    "            Y = norm_array(Y, 4)\n",
    "            notes_to_np(notes)\n",
    "            unique_chords = create_unique_chords(X, unique_chords)\n",
    "            unique_chords = create_unique_chords(Y, unique_chords)\n",
    "            unique_chords = unique_chords.reshape((-1, 4))\n",
    "            unique_chords = np.unique(unique_chords, axis=0)\n",
    "            unique_chords = list(unique_chords)\n",
    "            coded_X = []\n",
    "            coded_Y = []\n",
    "            coded_X = create_coded(X)\n",
    "            coded_Y = create_coded(Y)\n",
    "            encode(X, coded_X)\n",
    "            encode(Y, coded_Y)\n",
    "            X = np.array(coded_X)\n",
    "            y = np.array(coded_Y)\n",
    "            X_notes = notes\n",
    "            X_notes = X_notes[:len(X)]\n",
    "            X = X[:len(X_notes)]\n",
    "            y = y[:len(X)]\n",
    "            if (i < 27100):\n",
    "                merged_model.fit([X, X_notes], y, epochs=1, batch_size=1, verbose=1)\n",
    "                merged_model.reset_states()\n",
    "            else:\n",
    "                y_pred.append(merged_model.predict([X, X_notes], batch_size=1, verbose=1).argmax(axis=1))\n",
    "                y_real.append(y)\n",
    "            \n",
    "            \n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(unique_chords)\n",
    "df.to_csv(\"vocab.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(\"vocab.csv\")\n",
    "x = x.values.T[1:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "758"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_chords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model.save(\"NN_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
